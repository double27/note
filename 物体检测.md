# 一. 概述：
![](./picture/decetion.jpg)

“物体检测”主要解决两个问题：图像上多个目标在哪里（位置），是什么（类别）

# 二. 输入与输出
输入一张图像（把图像作为输入），计算机的是一个由像素值组成的数组。
输出一张图像，包括图像中包含的物体，与物体的轮廓。

# 三. 计算机的任务
我们希望计算机能够从输入的所有图像获取其独特的特征，生成一些选择框区域，判断区域内是物体还是背景。
<br>接着对前景区域，根据不同类别的不同特征，判断前景区域属于哪个类别，最终给出图片中所有的物体及物体所处的区域。


#四. Faster-RCNN:
![GitHub](./picture/faster_rcnn.jpg "GitHub,Social Coding")

Faster RCNN的基本思路：同时解决定位（localization） + 检测（detection）
<br><br>多任务学习，带有两个输出分支。
- 一个分支用于做图像分类，即全连接+softmax判断目标类别，和单纯图像分类区别在于这里还另外需要一个“背景”类。
- 另一个分支用于判断目标位置，即完成回归任务输出四个数字标记包围盒位置(例如中心点横纵坐标和包围盒长宽)，该分支输出结果只有在分类分支判断不为“背景”时才使用。

## 1. 特征抽取
    通过卷积神经网络，如VGG-16，抽取特征，获取FeatureMap
## 2. RPN（RegionProposal Network， 区域生成网络）
1. 生成anchors，FeatureMap的每个点生成k个不同长宽比例、不同面积区域的anchors
2. 用3*3的卷积核对上一步骤得到的FeatureMap做卷积计算，加入附近像素的信息
3. 分两路，一路用来判断候选框是前景还是背景，另一路用来确定候选框的位置
    1. 用2k个卷积核对FeatureMap做卷积，得到2k个FeatureMap，先reshape成一维向量，然后softmax来判断是前景还是背景，然后reshape恢复为二维feature map
    2. 用4k个1 * 1 * 512 的卷积核卷积，最后输出4k个数，这里的4是一个建议框的参数，即(x, y, w, h)  
4 根据anchor的概率（rpn_cls_prob）和位置（bbox_pred）选出rois：按照前景概率得分筛出前TopN个bbox，再通过[NMS](https://blog.csdn.net/num270710/article/details/86508048)后保留前TopN2 个bbox 
## 3. ROI Pooling层
>解决之前得到的proposal大小形状各不相同，导致没法做全连接。
<br><br>RoI Pooling 是对输入R-CNN子网络的数据进行准备的关键操作。我们得到的区域常常有不同的大小，在映射到feature map上之后，会得到不同大小的特征张量。RoI Pooling先将RoI等分成目标个数的网格，再在每个网格上进行max pooling，就得到等长的RoI feature vector。
## 4. 分类层
>ROI Pooling层后的特征图，通过全连接层与softmax，就可以计算属于哪个具体类别，比如人，狗，飞机，并可以得到cls_prob概率向量。同时再次利用bounding box regression精细调整proposal位置，得到bbox_pred，用于回归更加精确的目标检测框。
<br><br>这样就完成了faster R-CNN的整个过程了。算法还是相当复杂的，对于每个细节需要反复理解。faster R-CNN使用resNet101模型作为卷积层，

#  五. 演示
PASCAL VOC 2007样本集上既有图像中物体类别标签，也有图像中物体位置标签；
<br>


参考：
- [目标检测算法综述：R-CNN，faster R-CNN，yolo，SSD，yoloV2](https://www.imooc.com/article/37757)
- [基础目标检测算法介绍：CNN、RCNN、Fast RCNN和Faster](http://www.sohu.com/a/289552408_100270933)